hour < 7 ~ "Overnight",
hour >= 7 & hour < 10 ~ "AM Rush",
hour >= 10 & hour < 15 ~ "Mid-Day",
hour >= 15 & hour <= 18 ~ "PM Rush",
hour > 18 ~ "Evening"
),
# Ensure weekend is a factor with both levels
weekend_label = ifelse(weekend == 1, "Weekend", "Weekday")
)
# Scatter plot by time and day type
test %>%
filter(!is.na(pred2), !is.na(Trip_Count), !is.na(weekend_label), !is.na(time_of_day)) %>%
ggplot(aes(x = Trip_Count, y = pred2)) +
geom_point(alpha = 0.2, color = "#3182bd") +
geom_abline(slope = 1, intercept = 0, color = "red", linewidth = 1) +
geom_smooth(method = "lm", se = FALSE, color = "darkgreen") +
facet_grid(weekend_label ~ time_of_day) +
labs(
title = "Observed vs. Predicted Bike Trips",
subtitle = "Model 2 performance by time period",
x = "Observed Trips",
y = "Predicted Trips",
caption = "Red line = perfect predictions; Green line = actual model fit"
) +
plotTheme
# Calculate MAE by station
station_errors <- test %>%
filter(!is.na(pred2), !is.na(abs_error)) %>%
group_by(start_station) %>%
summarize(
MAE = mean(abs_error, na.rm = TRUE),
avg_demand = mean(Trip_Count, na.rm = TRUE),
.groups = "drop"
)
# Get coordinates from test data itself (it has .x and .y versions)
# Use .x version (usually from the first join)
station_coords <- test %>%
group_by(start_station) %>%
summarize(
station_lat = first(na.omit(start_lat.x)),
station_lon = first(na.omit(start_lon.x)),
.groups = "drop"
) %>%
filter(!is.na(station_lat), !is.na(station_lon))
# Join errors with coordinates
station_errors <- station_errors %>%
left_join(station_coords, by = "start_station") %>%
filter(!is.na(station_lat), !is.na(station_lon))
# Map 1: Prediction Errors
p1 <- ggplot() +
geom_sf(data = philly_census, fill = "grey95", color = "white", size = 0.2) +
geom_point(
data = station_errors,
aes(x = station_lon, y = station_lat, color = MAE),
size = 3.5,
alpha = 0.7
) +
scale_color_viridis(
option = "plasma",
name = "MAE (trips)",
direction = -1
) +
labs(title = "Prediction Errors") +
mapTheme
# Map 2: Average Demand
p2 <- ggplot() +
geom_sf(data = philly_census, fill = "grey95", color = "white", size = 0.2) +
geom_point(
data = station_errors,
aes(x = station_lon, y = station_lat, color = avg_demand),
size = 3.5,
alpha = 0.7
) +
scale_color_viridis(
option = "viridis",
name = "Avg Demand",
direction = -1
) +
labs(title = "Average Demand") +
mapTheme
# Combine maps
library(gridExtra)
grid.arrange(p1, p2, ncol = 2)
# MAE by time of day and day type
temporal_errors <- test %>%
group_by(time_of_day, weekend) %>%
summarize(
MAE = mean(abs_error, na.rm = TRUE),
.groups = "drop"
) %>%
mutate(day_type = ifelse(weekend == 1, "Weekend", "Weekday"))
ggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = day_type)) +
geom_col(position = "dodge") +
scale_fill_manual(values = c("Weekday" = "#08519c", "Weekend" = "#6baed6")) +
labs(
title = "Prediction Errors by Time Period",
subtitle = "When is the model struggling most?",
x = "Time of Day",
y = "Mean Absolute Error (trips)",
fill = "Day Type"
) +
plotTheme +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Join demographic data to station errors
station_errors_demo <- station_errors %>%
left_join(
station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),
by = "start_station"
) %>%
filter(!is.na(Med_Inc))
# Create plots
p1 <- ggplot(station_errors_demo, aes(x = Med_Inc, y = MAE)) +
geom_point(alpha = 0.5, color = "#3182bd") +
geom_smooth(method = "lm", se = FALSE, color = "red") +
scale_x_continuous(labels = scales::dollar) +
labs(title = "Errors vs. Median Income", x = "Median Income", y = "MAE") +
plotTheme
p2 <- ggplot(station_errors_demo, aes(x = Percent_Taking_Transit, y = MAE)) +
geom_point(alpha = 0.5, color = "#3182bd") +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Errors vs. Transit Usage", x = "% Taking Transit", y = "MAE") +
plotTheme
p3 <- ggplot(station_errors_demo, aes(x = Percent_White, y = MAE)) +
geom_point(alpha = 0.5, color = "#3182bd") +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Errors vs. Race", x = "% White", y = "MAE") +
plotTheme
grid.arrange(p1, p2, p3, ncol = 2)
# Read Q3 2024 data
indego_hw <- read_csv("data/indego-trips-2024-q3.csv")
cat("Total trips in Q3 2024:", format(nrow(indego_hw), big.mark = ","), "\n")
cat("Date range:",
min(mdy_hm(indego_hw$start_time)), "to",
max(mdy_hm(indego_hw$start_time)), "\n")
# Read Q3 2024 data
indego_hw <- read_csv("data/indego-trips-2024-q3.csv")
cat("Total trips in Q3 2024:", format(nrow(indego_hw), big.mark = ","), "\n")
cat("Date range:",
min(mdy_hm(indego_hw$start_time)), "to",
max(mdy_hm(indego_hw$start_time)), "\n")
indego_hw <- indego_hw %>%
mutate(
start_datetime = mdy_hm(start_time),
end_datetime = mdy_hm(end_time),
interval60 = floor_date(start_datetime, unit = "hour"),
week = week(interval60),
month = month(interval60, label = TRUE),
dotw = wday(interval60, label = TRUE),
hour = hour(interval60),
date = as.Date(interval60),
weekend = ifelse(dotw %in% c("Sat", "Sun"), 1, 0),
rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)
)
daily_trips_hw <- indego_hw %>%
group_by(date) %>%
summarize(trips = n())
ggplot(daily_trips_hw, aes(x = date, y = trips)) +
geom_line(color = "#3182bd", linewidth = 1) +
geom_smooth(se = FALSE, color = "red", linetype = "dashed") +
scale_y_continuous(labels = scales::comma) +
labs(
title = "Indego Daily Ridership - Q3 2024 (Summer)",
subtitle = "Peak biking season in Philadelphia",
x = "Date",
y = "Daily Trips"
) +
plotTheme
hourly_patterns_hw <- indego_hw %>%
group_by(hour, weekend) %>%
summarize(avg_trips = n() / n_distinct(date), .groups = "drop") %>%
mutate(day_type = ifelse(weekend == 1, "Weekend", "Weekday"))
ggplot(hourly_patterns_hw, aes(x = hour, y = avg_trips, color = day_type)) +
geom_line(linewidth = 1.2) +
scale_color_manual(values = c("Weekday" = "#08519c", "Weekend" = "#6baed6")) +
labs(
title = "Average Hourly Ridership Patterns - Q3 2024",
x = "Hour",
y = "Average Trips per Hour",
color = "Day Type"
) +
plotTheme
# Q3 2024: July 1 - September 30
weather_hw <- riem_measures(
station = "PHL",
date_start = "2024-07-01",
date_end = "2024-09-30"
)
weather_processed_hw <- weather_hw %>%
mutate(
interval60 = floor_date(valid, unit = "hour"),
Temperature = tmpf,
Precipitation = ifelse(is.na(p01i), 0, p01i),
Wind_Speed = sknt
) %>%
select(interval60, Temperature, Precipitation, Wind_Speed) %>%
distinct() %>%
complete(interval60 = seq(min(interval60), max(interval60), by = "hour")) %>%
fill(Temperature, Precipitation, Wind_Speed, .direction = "down")
ggplot(weather_processed_hw, aes(x = interval60, y = Temperature)) +
geom_line(color = "#3182bd", alpha = 0.7) +
geom_smooth(se = FALSE, color = "red") +
labs(
title = "Philadelphia Temperature - Q3 2024 (Summer)",
x = "Date",
y = "Temperature (Â°F)"
) +
plotTheme
# Note: You need to join census data first
# Reuse the chicagoCensus and spatial join code from above
trips_panel_hw <- indego_hw %>%
group_by(interval60, start_station, start_lat, start_lon) %>%
summarize(Trip_Count = n(), .groups = "drop")
study_panel_hw <- expand.grid(
interval60 = unique(trips_panel_hw$interval60),
start_station = unique(trips_panel_hw$start_station),
stringsAsFactors = FALSE
) %>%
left_join(trips_panel_hw, by = c("interval60", "start_station")) %>%
mutate(Trip_Count = replace_na(Trip_Count, 0))
station_attributes_hw <- trips_panel_hw %>%
group_by(start_station) %>%
summarize(
start_lat = first(start_lat),
start_lon = first(start_lon),
.groups = "drop"
)
study_panel_hw <- study_panel_hw %>%
left_join(station_attributes_hw, by = "start_station")
study_panel_hw <- study_panel_hw %>%
mutate(
week = week(interval60),
month = month(interval60, label = TRUE),
dotw = wday(interval60, label = TRUE),
hour = hour(interval60),
date = as.Date(interval60),
weekend = ifelse(dotw %in% c("Sat", "Sun"), 1, 0),
rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)
) %>%
left_join(weather_processed_hw, by = "interval60")
study_panel_hw <- study_panel_hw %>%
arrange(start_station, interval60) %>%
group_by(start_station) %>%
mutate(
lag1Hour = lag(Trip_Count, 1),
lag2Hours = lag(Trip_Count, 2),
lag3Hours = lag(Trip_Count, 3),
lag12Hours = lag(Trip_Count, 12),
lag1day = lag(Trip_Count, 24)
) %>%
ungroup()
study_panel_complete_hw <- study_panel_hw %>%
filter(!is.na(lag1day))
# Q3 2024: weeks 27-39 (July-September)
# Train: weeks 27-35 (July-August)
# Test: weeks 36-39 (September)
early_stations_hw <- study_panel_complete_hw %>%
filter(week < 36, Trip_Count > 0) %>%
distinct(start_station) %>%
pull(start_station)
late_stations_hw <- study_panel_complete_hw %>%
filter(week >= 36, Trip_Count > 0) %>%
distinct(start_station) %>%
pull(start_station)
common_stations_hw <- intersect(early_stations_hw, late_stations_hw)
study_panel_complete_hw <- study_panel_complete_hw %>%
filter(start_station %in% common_stations_hw) %>%
mutate(dotw_simple = as.factor(dotw))
train_hw <- study_panel_complete_hw %>% filter(week < 36)
test_hw <- study_panel_complete_hw %>% filter(week >= 36) %>%
mutate(dotw_simple = factor(dotw, levels = levels(train_hw$dotw_simple)))
cat("Training observations:", format(nrow(train_hw), big.mark = ","), "\n")
cat("Testing observations:", format(nrow(test_hw), big.mark = ","), "\n")
# Model 1: Time + Weather
model1_hw <- lm(
Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,
data = train_hw
)
# Model 2: + Temporal Lags
model2_hw <- lm(
Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
lag1Hour + lag3Hours + lag1day,
data = train_hw
)
# Models 3-5: Continue adding features...
# (Reference the Q1 code above)
test_hw <- test_hw %>%
mutate(
pred1 = predict(model1_hw, newdata = test_hw),
pred2 = predict(model2_hw, newdata = test_hw)
# pred3, pred4, pred5...
)
mae_results_hw <- tibble(
Model = c("1. Time + Weather", "2. + Temporal Lags"),
MAE = c(
mean(abs(test_hw$Trip_Count - test_hw$pred1), na.rm = TRUE),
mean(abs(test_hw$Trip_Count - test_hw$pred2), na.rm = TRUE)
)
)
kable(mae_results_hw, digits = 3) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
test_hw <- test_hw %>%
mutate(
error = Trip_Count - pred2,
abs_error = abs(error),
time_of_day = case_when(
hour < 7 ~ "Overnight",
hour >= 7 & hour < 10 ~ "AM Rush",
hour >= 10 & hour < 15 ~ "Mid-Day",
hour >= 15 & hour <= 18 ~ "PM Rush",
hour > 18 ~ "Evening"
)
)
station_errors_hw <- test_hw %>%
group_by(start_station, start_lat, start_lon) %>%
summarize(
MAE = mean(abs_error, na.rm = TRUE),
avg_demand = mean(Trip_Count, na.rm = TRUE),
.groups = "drop"
)
# Calculate errors
test_hw <- test_hw %>%
mutate(
error = Trip_Count - pred2,
abs_error = abs(error),
time_of_day = case_when(
hour < 7 ~ "Overnight",
hour >= 7 & hour < 10 ~ "AM Rush",
hour >= 10 & hour < 15 ~ "Mid-Day",
hour >= 15 & hour <= 18 ~ "PM Rush",
hour > 18 ~ "Evening"
)
)
# Calculate MAE by station
station_errors_hw <- test_hw %>%
group_by(start_station) %>%
summarize(
MAE = mean(abs_error, na.rm = TRUE),
avg_demand = mean(Trip_Count, na.rm = TRUE),
.groups = "drop"
)
# Get coordinates from test_hw (using .x version)
station_coords_hw <- test_hw %>%
group_by(start_station) %>%
summarize(
start_lat = first(na.omit(start_lat.x)),
start_lon = first(na.omit(start_lon.x)),
.groups = "drop"
) %>%
filter(!is.na(start_lat), !is.na(start_lon))
# Join coordinates
station_errors_hw <- station_errors_hw %>%
left_join(station_coords_hw, by = "start_station") %>%
filter(!is.na(start_lat), !is.na(start_lon))
# Create map
ggplot(station_errors_hw, aes(x = start_lon, y = start_lat)) +
geom_point(aes(color = MAE, size = avg_demand), alpha = 0.6) +
scale_color_viridis(option = "plasma") +
labs(title = "Spatial Distribution of Errors - Q3 2024") +
theme_minimal()
# Calculate errors
test_hw <- test_hw %>%
mutate(
error = Trip_Count - pred2,
abs_error = abs(error),
time_of_day = case_when(
hour < 7 ~ "Overnight",
hour >= 7 & hour < 10 ~ "AM Rush",
hour >= 10 & hour < 15 ~ "Mid-Day",
hour >= 15 & hour <= 18 ~ "PM Rush",
hour > 18 ~ "Evening"
)
)
# Calculate MAE by station
station_errors_hw <- test_hw %>%
group_by(start_station) %>%
summarize(
MAE = mean(abs_error, na.rm = TRUE),
avg_demand = mean(Trip_Count, na.rm = TRUE),
.groups = "drop"
)
# Get coordinates from test_hw (using .x version)
station_coords_hw <- test_hw %>%
group_by(start_station) %>%
summarize(
start_lat = first(na.omit(start_lat.x)),
start_lon = first(na.omit(start_lon.x)),
.groups = "drop"
) %>%
filter(!is.na(start_lat), !is.na(start_lon))
# Join coordinates
station_errors_hw <- station_errors_hw %>%
left_join(station_coords_hw, by = "start_station") %>%
filter(!is.na(start_lat), !is.na(start_lon))
# Create map
ggplot(station_errors_hw, aes(x = start_lon, y = start_lat)) +
geom_point(aes(color = MAE, size = avg_demand), alpha = 0.6) +
scale_color_viridis(option = "plasma") +
labs(title = "Spatial Distribution of Errors - Q3 2024") +
theme_minimal()
temporal_errors_hw <- test_hw %>%
group_by(time_of_day, weekend) %>%
summarize(MAE = mean(abs_error, na.rm = TRUE), .groups = "drop") %>%
mutate(day_type = ifelse(weekend == 1, "Weekend", "Weekday"))
ggplot(temporal_errors_hw, aes(x = time_of_day, y = MAE, fill = day_type)) +
geom_col(position = "dodge") +
labs(title = "Prediction Errors by Time Period - Q3 2024") +
plotTheme
train_hw <- train_hw %>%
mutate(
perfect_weather = ifelse(
Temperature >= 65 & Temperature <= 80 &
Precipitation == 0 &
Wind_Speed < 15,
1, 0
)
)
test_hw <- test_hw %>%
mutate(
perfect_weather = ifelse(
Temperature >= 65 & Temperature <= 80 &
Precipitation == 0 &
Wind_Speed < 15,
1, 0
)
)
train_hw <- train_hw %>%
arrange(start_station, interval60) %>%
group_by(start_station) %>%
mutate(
lag7day_avg = zoo::rollmean(Trip_Count, k = 168, fill = NA, align = "right")
) %>%
ungroup()
test_hw <- test_hw %>%
arrange(start_station, interval60) %>%
group_by(start_station) %>%
mutate(
lag7day_avg = zoo::rollmean(Trip_Count, k = 168, fill = NA, align = "right")
) %>%
ungroup()
model6_hw <- lm(
Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
lag1Hour + lag3Hours + lag1day + lag7day_avg +
perfect_weather + perfect_weather * weekend +
as.factor(start_station),
data = train_hw %>% filter(!is.na(lag7day_avg))
)
# Predict and calculate MAE
test_hw <- test_hw %>%
filter(!is.na(lag7day_avg)) %>%
mutate(pred6 = predict(model6_hw, newdata = .))
mae_model6 <- mean(abs(test_hw$Trip_Count - test_hw$pred6), na.rm = TRUE)
cat("Model 6 MAE:", round(mae_model6, 3), "\n")
mae_all <- mae_results_hw %>%
add_row(Model = "6. + Enhanced Features", MAE = round(mae_model6, 3))
improvement <- round(100 * (mae_results_hw$MAE[2] - mae_model6) / mae_results_hw$MAE[2], 1)
ggplot(mae_all, aes(x = reorder(Model, -MAE), y = MAE)) +
geom_col(aes(fill = Model == "6. + Enhanced Features")) +
scale_fill_manual(values = c("FALSE" = "#3182bd", "TRUE" = "#e41a1c")) +
labs(
title = "Impact of Feature Engineering",
subtitle = paste0("Improvement: ", improvement, "% error reduction")
) +
guides(fill = "none") +
plotTheme +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
model_poisson_hw <- glm(
Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + lag1Hour + lag3Hours + lag1day,
data = train_hw,
family = poisson(link = "log")
)
test_hw <- test_hw %>%
mutate(pred_poisson = predict(model_poisson_hw, newdata = test_hw, type = "response"))
mae_poisson <- mean(abs(test_hw$Trip_Count - test_hw$pred_poisson), na.rm = TRUE)
tibble(
Model = c("Linear Regression", "Poisson Regression"),
MAE = round(c(mae_model6, mae_poisson), 3)
) %>%
kable() %>%
kable_styling()
avg_demand <- mean(test_hw$Trip_Count, na.rm = TRUE)
error_pct <- round(100 * mae_model6 / avg_demand, 1)
cat("Q3 average demand:", round(avg_demand, 2), "trips/hour\n")
cat("MAE as % of average:", error_pct, "%\n")
indego_hw <- indego_hw %>%
mutate(
start_datetime = mdy_hm(start_time),
end_datetime = mdy_hm(end_time),
interval60 = floor_date(start_datetime, unit = "hour"),
week = week(interval60),
month = month(interval60, label = TRUE),
dotw = wday(interval60, label = TRUE),
hour = hour(interval60),
date = as.Date(interval60),
weekend = ifelse(dotw %in% c("Sat", "Sun"), 1, 0),
rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)
)
daily_trips_hw <- indego_hw %>%
group_by(date) %>%
summarize(trips = n())
ggplot(daily_trips_hw, aes(x = date, y = trips)) +
geom_line(color = "#3182bd", linewidth = 1) +
geom_smooth(se = FALSE, color = "red", linetype = "dashed") +
scale_y_continuous(labels = scales::comma) +
labs(
title = "Indego Daily Ridership - Q3 2024 (Summer)",
subtitle = "Peak biking season in Philadelphia",
x = "Date",
y = "Daily Trips"
) +
plotTheme
setwd("E:/MUSA/MUSA 5080/portfolio-setup-XZC-debug/assignments/final_project_presentation")
setwd("E:/MUSA/MUSA 5080/portfolio-setup-XZC-debug/docs/assignments/final_project_presentation")
