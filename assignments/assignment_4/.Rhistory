fun = mean,
na.rm = TRUE
)[, 2]
)
ggplot() +
geom_sf(data = fishnet, aes(fill = kde_value), color = NA) +
geom_sf(data = chicagoBoundary, fill = NA, color = "white", linewidth = 1) +
scale_fill_viridis_c(
name = "KDE Value",
option = "plasma"
) +
labs(
title = "Kernel Density Baseline Prediction",
subtitle = "Simple spatial smoothing of 2017 burglary locations"
) +
theme_crime()
# Aggregate graffiti to fishnet
graffiti_fishnet <- st_join(graffiti, fishnet, join = st_within) %>%
st_drop_geometry() %>%
group_by(uniqueID) %>%
summarize(graffiti_count = n())
# Join to fishnet
fishnet <- fishnet %>%
left_join(graffiti_fishnet, by = "uniqueID") %>%
mutate(graffiti_count = replace_na(graffiti_count, 0))
cat("Graffiti count distribution:\n")
print(summary(fishnet$graffiti_count))
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(fishnet))
graffiti_coords <- st_coordinates(graffiti)
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# 调试代码
if(nrow(graffiti) == 0) {
stop("ERROR: graffiti 数据集是空的！检查文件是否存在")
}
if(!inherits(graffiti, "sf")) {
stop("ERROR: graffiti 不是 sf 对象！检查数据转换代码")
}
cat("✓ graffiti 有", nrow(graffiti), "条记录\n")
cat("✓ fishnet_coords:", nrow(fishnet_coords), "行\n")
cat("✓ graffiti_coords:", nrow(graffiti_coords), "行\n")
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# 调试代码
if(nrow(graffiti) == 0) {
stop("ERROR: graffiti 数据集是空的！检查文件是否存在")
}
if(!inherits(graffiti, "sf")) {
stop("ERROR: graffiti 不是 sf 对象！检查数据转换代码")
}
cat("✓ graffiti 有", nrow(graffiti), "条记录\n")
cat("✓ fishnet_coords:", nrow(fishnet_coords), "行\n")
cat("✓ graffiti_coords:", nrow(graffiti_coords), "行\n")
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
graffiti <- read_csv(here("data", "graffiti_2017.csv")) %>%
# 2017
filter(year(`Creation Date`) == 2017 | year(`Created Date`) == 2017) %>%
filter(!is.na(Latitude), !is.na(Longitude)) %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>%
st_transform('ESRI:102271')
# 查看你的 graffiti 数据结构
graffiti_raw <- read_csv(here("data", "graffiti_2017.csv"))
# 查看你的 graffiti 数据结构
graffiti_raw <- read_csv("data/graffiti_2017.csv")
# 查看你的 graffiti 数据结构
graffiti_raw <- read_csv("data/Crimes_-_2017_20251114.csv")
names(graffiti_raw)  # 查看列名
table(year(graffiti_raw$`Creation Date`))  # 查看年份分布
cat("Filtered graffiti records:", nrow(graffiti), "\n")
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# 查看你的 graffiti 数据结构
graffiti_raw <- read_csv("data/311_Service_Requests_-_Graffiti_Removal_-_Historical_20251114.csv")
names(graffiti_raw)  # 查看列名
table(year(graffiti_raw$`Creation Date`))  # 查看年份分布
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# Create spatial weights (5 nearest neighbors)
coords <- st_coordinates(st_centroid(fishnet))
neighbors <- knn2nb(knearneigh(coords, k = 5))
weights <- nb2listw(neighbors, style = "W", zero.policy = TRUE)
# Calculate Local Moran's I
local_moran <- localmoran(fishnet$graffiti_count, weights)
# Extract results
fishnet <- fishnet %>%
mutate(
local_i = local_moran[, 1],
p_value = local_moran[, 5],
is_significant = p_value < 0.05
)
# Calculate mean for classification
mean_graffiti <- mean(fishnet$graffiti_count, na.rm = TRUE)
# Classify clusters
fishnet <- fishnet %>%
mutate(
moran_class = case_when(
!is_significant ~ "Not Significant",
local_i > 0 & graffiti_count > mean_graffiti ~ "High-High",
local_i > 0 & graffiti_count <= mean_graffiti ~ "Low-Low",
local_i < 0 & graffiti_count > mean_graffiti ~ "High-Low",
local_i < 0 & graffiti_count <= mean_graffiti ~ "Low-High",
TRUE ~ "Not Significant"
)
)
# Count each type
table(fishnet$moran_class)
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# Calculate k-nearest neighbors
if(nrow(graffiti) > 100000) {
cat("oversize (", nrow(graffiti), "items)，Random sampling resulted in 60,000 items.\n")
graffiti <- graffiti %>% slice_sample(n = 60000)
graffiti_coords <- st_coordinates(graffiti)
}
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# Add to fishnet
fishnet <- fishnet %>%
mutate(
graffiti_nn = rowMeans(nn_result$nn.dist)
)
cat("Mean distance to 3 nearest graffiti locations:\n")
print(summary(fishnet$graffiti_nn))
ggplot() +
geom_sf(
data = fishnet,
aes(fill = moran_class),
color = NA
) +
scale_fill_manual(
values = c(
"High-High" = "#d7191c",
"High-Low" = "#fdae61",
"Low-High" = "#abd9e9",
"Low-Low" = "#2c7bb6",
"Not Significant" = "gray90"
),
name = "Cluster Type"
) +
labs(
title = "Local Moran's I: Graffiti Clusters",
subtitle = "High-High clusters indicate concentrated disorder hotspots"
) +
theme_crime()
# Get centroids of High-High cells
hotspots <- fishnet %>%
filter(moran_class == "High-High") %>%
st_centroid()
# Calculate distance to nearest hotspot
if (nrow(hotspots) > 0) {
fishnet <- fishnet %>%
mutate(
dist_to_hotspot = as.numeric(
st_distance(st_centroid(fishnet), hotspots %>% st_union())
)
)
cat("Number of graffiti hotspot cells:", nrow(hotspots), "\n")
cat("Distance to hotspot summary:\n")
print(summary(fishnet$dist_to_hotspot))
} else {
fishnet <- fishnet %>%
mutate(dist_to_hotspot = 0)
cat("No significant hotspots identified\n")
}
# Spatial join with police districts
fishnet <- st_join(
fishnet,
policeDistricts,
join = st_within,
left = TRUE
) %>%
filter(!is.na(District))
cat("Number of police districts:", length(unique(fishnet$District)), "\n")
cat("Grid cells after joining districts:", nrow(fishnet), "\n")
# Create modeling dataset
fishnet_model <- fishnet %>%
st_drop_geometry() %>%
dplyr::select(
uniqueID,
District,
countBurglaries,
graffiti_count,
graffiti_nn,
dist_to_hotspot
) %>%
na.omit()
cat("Modeling dataset:\n")
cat("  Observations:", nrow(fishnet_model), "\n")
cat("  Variables:", ncol(fishnet_model), "\n")
# Fit Poisson regression
model_poisson <- glm(
countBurglaries ~ graffiti_count + graffiti_nn + dist_to_hotspot,
data = fishnet_model,
family = "poisson"
)
# Display results
summary(model_poisson)
# Calculate dispersion parameter
dispersion <- sum(residuals(model_poisson, type = "pearson")^2) /
model_poisson$df.residual
cat("Dispersion parameter:", round(dispersion, 2), "\n")
if (dispersion > 1.5) {
cat("Overdispersion detected - Negative Binomial model recommended\n")
} else {
cat("Poisson model appears appropriate\n")
}
# Fit Negative Binomial model
model_nb <- glm.nb(
countBurglaries ~ graffiti_count + graffiti_nn + dist_to_hotspot,
data = fishnet_model
)
# Display results
summary(model_nb)
# Compare models using AIC (lower is better)
cat("\nModel comparison:\n")
cat("Poisson AIC:", round(AIC(model_poisson), 1), "\n")
cat("Negative Binomial AIC:", round(AIC(model_nb), 1), "\n")
cat("Difference:", round(AIC(model_poisson) - AIC(model_nb), 1), "\n")
# Get unique districts
districts <- unique(fishnet_model$District)
cv_results <- tibble()
cat("Running Leave-One-Group-Out Cross-Validation...\n\n")
for (i in seq_along(districts)) {
test_district <- districts[i]
# Split data by district
train_data <- fishnet_model %>% filter(District != test_district)
test_data <- fishnet_model %>% filter(District == test_district)
# Fit model on training data
model_cv <- glm.nb(
countBurglaries ~ graffiti_count + graffiti_nn + dist_to_hotspot,
data = train_data
)
# Predict on test data
test_data <- test_data %>%
mutate(
prediction = predict(model_cv, test_data, type = "response")
)
# Calculate error metrics
mae <- mean(abs(test_data$countBurglaries - test_data$prediction))
rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))
# Store results
cv_results <- bind_rows(
cv_results,
tibble(
fold = i,
test_district = test_district,
n_test = nrow(test_data),
mae = mae,
rmse = rmse
)
)
cat("Fold", i, "/", length(districts), "- District", test_district,
"- MAE:", round(mae, 2), "\n")
}
cat("\nCross-validation complete\n")
cat("Mean MAE:", round(mean(cv_results$mae), 2), "burglaries per cell\n")
cat("Mean RMSE:", round(mean(cv_results$rmse), 2), "burglaries per cell\n")
cv_results %>%
arrange(desc(mae)) %>%
mutate(across(c(mae, rmse), ~round(., 2))) %>%
kable(
caption = "Spatial Cross-Validation Results by Police District",
col.names = c("Fold", "District", "N Test", "MAE", "RMSE")
) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
# Fit final model on all 2017 data
final_model <- glm.nb(
countBurglaries ~ graffiti_count + graffiti_nn + dist_to_hotspot,
data = fishnet_model
)
# Add predictions to fishnet
fishnet <- fishnet %>%
mutate(
prediction_nb = predict(
final_model,
fishnet_model,
type = "response"
)[match(uniqueID, fishnet_model$uniqueID)]
)
# Normalize KDE to same scale
kde_sum <- sum(fishnet$kde_value, na.rm = TRUE)
count_sum <- sum(fishnet$countBurglaries, na.rm = TRUE)
fishnet <- fishnet %>%
mutate(
prediction_kde = (kde_value / kde_sum) * count_sum
)
# Create comparison maps
p1 <- ggplot() +
geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +
scale_fill_viridis_c(name = "Count", option = "plasma", limits = c(0, 15)) +
labs(title = "Actual Burglaries (2017)") +
theme_crime()
p2 <- ggplot() +
geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +
scale_fill_viridis_c(name = "Predicted", option = "plasma", limits = c(0, 15)) +
labs(title = "Model Predictions (Neg. Binomial)") +
theme_crime()
p3 <- ggplot() +
geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +
scale_fill_viridis_c(name = "Predicted", option = "plasma", limits = c(0, 15)) +
labs(title = "KDE Baseline Predictions") +
theme_crime()
p1 + p2 + p3
# Calculate performance metrics
comparison <- fishnet %>%
st_drop_geometry() %>%
filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%
summarize(
model_mae = mean(abs(countBurglaries - prediction_nb)),
model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),
kde_mae = mean(abs(countBurglaries - prediction_kde)),
kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))
)
comparison %>%
pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
separate(metric, into = c("approach", "metric"), sep = "_") %>%
pivot_wider(names_from = metric, values_from = value) %>%
mutate(across(where(is.numeric), ~round(., 2))) %>%
kable(
caption = "Model Performance Comparison on 2017 Data",
col.names = c("Approach", "MAE", "RMSE")
) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
# Calculate errors
fishnet <- fishnet %>%
mutate(
error_nb = countBurglaries - prediction_nb,
abs_error_nb = abs(error_nb)
)
# Map signed errors
p1 <- ggplot() +
geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +
scale_fill_gradient2(
name = "Error",
low = "#2166ac", mid = "white", high = "#b2182b",
midpoint = 0,
limits = c(-10, 10)
) +
labs(
title = "Model Errors (Actual - Predicted)",
subtitle = "Blue = under-predicted, Red = over-predicted"
) +
theme_crime()
# Map absolute errors
p2 <- ggplot() +
geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +
scale_fill_viridis_c(name = "Abs. Error", option = "magma") +
labs(
title = "Absolute Model Errors",
subtitle = "Magnitude of prediction errors"
) +
theme_crime()
p1 + p2
# Load 2018 burglaries from Chicago crimes dataset
burglaries_2018 <- read_csv(here("data", "Crimes_-_2018.csv")) %>%
# Filter for burglary crimes only
filter(`Primary Type` == "BURGLARY") %>%
# Further filter for forcible entry to match 2017 data
filter(str_detect(Description, "FORCIBLE ENTRY")) %>%
# Remove records with missing coordinates
filter(!is.na(Latitude), !is.na(Longitude)) %>%
# Remove invalid coordinates
filter(Latitude > 41.6, Latitude < 42.1) %>%
filter(Longitude > -87.95, Longitude < -87.5) %>%
# Convert to spatial object
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>%
st_transform('ESRI:102271')
install.packages("gmodels")
install.packages("pROC")
library(gmodels)
library(pROC)
mydata <- read.csv("Logistic Regression Data.csv")
mydata <- read.csv("Logistic Regression Data.csv")
str(mydata)
summary(mydata)
DRINKING_D.tab <- table(mydata$DRINKING_D)
DRINKING_D.tab
prop.table(DRINKING_D.tab)
DRINKING_D.tab <- table(mydata$DRINKING_D)
DRINKING_D.tab
prop.table(DRINKING_D.tab)
CrossTable(
mydata$FATAL_OR_M,
mydata$DRINKING_D,
prop.r = FALSE,
prop.t = FALSE,
prop.chisq = FALSE,
chisq = TRUE
)
vars_bin <- c("OVERTURNED","CELL_PHONE","SPEEDING",
"AGGRESSIVE","DRIVER1617","DRIVER65PLUS")
for (v in vars_bin) {
cat("\n==========", v, "==========\n")
CrossTable(
mydata[[v]], mydata$DRINKING_D,
prop.r = FALSE, prop.t = FALSE,
prop.chisq = FALSE, chisq = TRUE
)
}
# 学历比例
tapply(mydata$PCTBACHMOR, mydata$DRINKING_D, mean, na.rm = TRUE)
tapply(mydata$PCTBACHMOR, mydata$DRINKING_D, sd,   na.rm = TRUE)
# 收入
tapply(mydata$MEDHHINC, mydata$DRINKING_D, mean, na.rm = TRUE)
tapply(mydata$MEDHHINC, mydata$DRINKING_D, sd,   na.rm = TRUE)
t.test(mydata$PCTBACHMOR ~ mydata$DRINKING_D)
t.test(mydata$MEDHHINC ~ mydata$DRINKING_D)
vars_all <- c("FATAL_OR_M","OVERTURNED","CELL_PHONE",
"SPEEDING","AGGRESSIVE","DRIVER1617",
"DRIVER65PLUS","PCTBACHMOR","MEDHHINC")
cor_mat <- cor(mydata[vars_all], use = "pairwise.complete.obs")
cor_mat
mylogit1 <- glm(
DRINKING_D ~ FATAL_OR_M + OVERTURNED + CELL_PHONE +
SPEEDING + AGGRESSIVE + DRIVER1617 + DRIVER65PLUS +
PCTBACHMOR + MEDHHINC,
data   = mydata,
family = binomial(link = "logit")
)
summary(mylogit1)
# 1) 取出系数矩阵（含 β、SE、z、p）
coefs <- summary(mylogit1)$coefficients
# 2) 计算 OR 和 CI
OR  <- exp(coefs[, "Estimate"])
CI_low  <- exp(coefs[, "Estimate"] - 1.96 * coefs[, "Std. Error"])
CI_high <- exp(coefs[, "Estimate"] + 1.96 * coefs[, "Std. Error"])
# 3) 合并
results1 <- cbind(
coefs,
OR      = OR,
CI_low  = CI_low,
CI_high = CI_high
)
round(results1, 3)
mydata$pred1 <- predict(mylogit1, type = "response")
summary(mydata$pred1)
calc_metrics <- function(cutoff, probs, y_true) {
y_pred <- ifelse(probs >= cutoff, 1, 0)
TP <- sum(y_true == 1 & y_pred == 1)
TN <- sum(y_true == 0 & y_pred == 0)
FP <- sum(y_true == 0 & y_pred == 1)
FN <- sum(y_true == 1 & y_pred == 0)
sensitivity <- TP / (TP + FN)     # 真阳性率
specificity <- TN / (TN + FP)     # 真阴性率
misclass    <- (FP + FN) / length(y_true)
data.frame(
cutoff      = cutoff,
sensitivity = sensitivity,
specificity = specificity,
misclass    = misclass
)
}
cutoffs <- c(0.02, 0.03, 0.05, 0.07, 0.08, 0.09, 0.10, 0.15, 0.20, 0.50)
metrics_list <- lapply(cutoffs, calc_metrics,
probs = mydata$pred1,
y_true = mydata$DRINKING_D)
metrics_tab <- do.call(rbind, metrics_list)
round(metrics_tab, 3)
roc_obj <- roc(mydata$DRINKING_D, mydata$pred1)
# 画图
plot(roc_obj, main = "ROC Curve for Logistic Model 1")
auc(roc_obj)
coords(roc_obj, "best", ret = c("threshold", "sensitivity", "specificity"),
best.method = "closest.topleft")
mylogit2 <- glm(
DRINKING_D ~ FATAL_OR_M + OVERTURNED + CELL_PHONE +
SPEEDING + AGGRESSIVE + DRIVER1617 + DRIVER65PLUS,
data   = mydata,
family = binomial
)
summary(mylogit2)
coefs2   <- summary(mylogit2)$coefficients
OR2      <- exp(coefs2[, "Estimate"])
CI_low2  <- exp(coefs2[, "Estimate"] - 1.96 * coefs2[, "Std. Error"])
CI_high2 <- exp(coefs2[, "Estimate"] + 1.96 * coefs2[, "Std. Error"])
results2 <- cbind(
coefs2,
OR      = OR2,
CI_low  = CI_low2,
CI_high = CI_high2
)
round(results2, 3)
AIC(mylogit1, mylogit2)
