# Density surface
p2 <- ggplot() +
geom_sf(data = chicagoBoundary, fill = "gray95", color = "gray60") +
geom_density_2d_filled(
data = data.frame(st_coordinates(burglaries)),
aes(X, Y),
alpha = 0.7,
bins = 8
) +
scale_fill_viridis_d(
option = "plasma",
direction = -1,
guide = "none"
) +
labs(
title = "Burglary Density Surface",
subtitle = "Kernel density estimation"
) +
theme_crime()
p1 + p2
# Load the graffiti data
# NOTE: Make sure you have downloaded graffiti_2017.csv to your data folder
graffiti <- read_csv("data/311_Service_Requests_-_Graffiti_Removal_-_Historical_20251114.csv") %>%
filter(!is.na(Latitude), !is.na(Longitude)) %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>%
st_transform('ESRI:102271')
cat("Number of graffiti removal requests:", nrow(graffiti), "\n")
p1 <- ggplot() +
geom_sf(data = chicagoBoundary, fill = "gray95", color = "gray60") +
geom_sf(data = graffiti, color = "#2a9d8f", size = 0.1, alpha = 0.4) +
labs(
title = "Graffiti Removal Requests (2017)",
subtitle = paste0("n = ", nrow(graffiti), " requests")
) +
theme_crime()
p2 <- ggplot() +
geom_sf(data = chicagoBoundary, fill = "gray95", color = "gray60") +
geom_density_2d_filled(
data = data.frame(st_coordinates(graffiti)),
aes(X, Y),
alpha = 0.7,
bins = 8
) +
scale_fill_viridis_d(
option = "mako",
direction = -1,
guide = "none"
) +
labs(
title = "Graffiti Request Density",
subtitle = "Spatial distribution pattern"
) +
theme_crime()
p1 + p2
# Create 500m x 500m grid
fishnet <- st_make_grid(
chicagoBoundary,
cellsize = 500,
square = TRUE
) %>%
st_sf() %>%
mutate(uniqueID = row_number())
# Keep only cells intersecting Chicago
fishnet <- fishnet[chicagoBoundary, ]
cat("Created", nrow(fishnet), "grid cells\n")
cat("Cell size: 500m x 500m\n")
cat("Cell area:", round(as.numeric(st_area(fishnet[1,])) / 1000000, 2), "km²\n")
# Spatial join: assign each burglary to a grid cell
burglaries_fishnet <- st_join(burglaries, fishnet, join = st_within) %>%
st_drop_geometry() %>%
group_by(uniqueID) %>%
summarize(countBurglaries = n())
# Join back to fishnet
fishnet <- fishnet %>%
left_join(burglaries_fishnet, by = "uniqueID") %>%
mutate(countBurglaries = replace_na(countBurglaries, 0))
# Distribution summary
cat("Burglary count distribution:\n")
summary_stats <- summary(fishnet$countBurglaries)
print(summary_stats)
cat("\nCells with zero burglaries:",
sum(fishnet$countBurglaries == 0),
"out of", nrow(fishnet),
paste0("(", round(100 * mean(fishnet$countBurglaries == 0), 1), "%)\n"))
ggplot() +
geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +
geom_sf(data = chicagoBoundary, fill = NA, color = "white", linewidth = 1) +
scale_fill_viridis_c(
name = "Burglaries",
option = "plasma",
trans = "sqrt",
breaks = c(0, 1, 5, 10, 20, 40)
) +
labs(
title = "Burglary Counts by Grid Cell",
subtitle = "500m x 500m cells, Chicago 2017"
) +
theme_crime()
# Convert to point pattern for spatstat
burglaries_ppp <- as.ppp(
st_coordinates(burglaries),
W = as.owin(st_bbox(chicagoBoundary))
)
# Calculate KDE with 1km bandwidth
kde_burglaries <- density.ppp(
burglaries_ppp,
sigma = 1000,
edge = TRUE
)
# Convert to raster and extract to fishnet
kde_raster <- rast(kde_burglaries)
fishnet <- fishnet %>%
mutate(
kde_value = terra::extract(
kde_raster,
vect(fishnet),
fun = mean,
na.rm = TRUE
)[, 2]
)
ggplot() +
geom_sf(data = fishnet, aes(fill = kde_value), color = NA) +
geom_sf(data = chicagoBoundary, fill = NA, color = "white", linewidth = 1) +
scale_fill_viridis_c(
name = "KDE Value",
option = "plasma"
) +
labs(
title = "Kernel Density Baseline Prediction",
subtitle = "Simple spatial smoothing of 2017 burglary locations"
) +
theme_crime()
# Aggregate graffiti to fishnet
graffiti_fishnet <- st_join(graffiti, fishnet, join = st_within) %>%
st_drop_geometry() %>%
group_by(uniqueID) %>%
summarize(graffiti_count = n())
# Join to fishnet
fishnet <- fishnet %>%
left_join(graffiti_fishnet, by = "uniqueID") %>%
mutate(graffiti_count = replace_na(graffiti_count, 0))
cat("Graffiti count distribution:\n")
print(summary(fishnet$graffiti_count))
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(fishnet))
graffiti_coords <- st_coordinates(graffiti)
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# 调试代码
if(nrow(graffiti) == 0) {
stop("ERROR: graffiti 数据集是空的！检查文件是否存在")
}
if(!inherits(graffiti, "sf")) {
stop("ERROR: graffiti 不是 sf 对象！检查数据转换代码")
}
cat("✓ graffiti 有", nrow(graffiti), "条记录\n")
cat("✓ fishnet_coords:", nrow(fishnet_coords), "行\n")
cat("✓ graffiti_coords:", nrow(graffiti_coords), "行\n")
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# 调试代码
if(nrow(graffiti) == 0) {
stop("ERROR: graffiti 数据集是空的！检查文件是否存在")
}
if(!inherits(graffiti, "sf")) {
stop("ERROR: graffiti 不是 sf 对象！检查数据转换代码")
}
cat("✓ graffiti 有", nrow(graffiti), "条记录\n")
cat("✓ fishnet_coords:", nrow(fishnet_coords), "行\n")
cat("✓ graffiti_coords:", nrow(graffiti_coords), "行\n")
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
graffiti <- read_csv(here("data", "graffiti_2017.csv")) %>%
# 2017
filter(year(`Creation Date`) == 2017 | year(`Created Date`) == 2017) %>%
filter(!is.na(Latitude), !is.na(Longitude)) %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>%
st_transform('ESRI:102271')
# 查看你的 graffiti 数据结构
graffiti_raw <- read_csv(here("data", "graffiti_2017.csv"))
# 查看你的 graffiti 数据结构
graffiti_raw <- read_csv("data/graffiti_2017.csv")
# 查看你的 graffiti 数据结构
graffiti_raw <- read_csv("data/Crimes_-_2017_20251114.csv")
names(graffiti_raw)  # 查看列名
table(year(graffiti_raw$`Creation Date`))  # 查看年份分布
cat("Filtered graffiti records:", nrow(graffiti), "\n")
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# 查看你的 graffiti 数据结构
graffiti_raw <- read_csv("data/311_Service_Requests_-_Graffiti_Removal_-_Historical_20251114.csv")
names(graffiti_raw)  # 查看列名
table(year(graffiti_raw$`Creation Date`))  # 查看年份分布
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# Calculate k-nearest neighbors
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# Create spatial weights (5 nearest neighbors)
coords <- st_coordinates(st_centroid(fishnet))
neighbors <- knn2nb(knearneigh(coords, k = 5))
weights <- nb2listw(neighbors, style = "W", zero.policy = TRUE)
# Calculate Local Moran's I
local_moran <- localmoran(fishnet$graffiti_count, weights)
# Extract results
fishnet <- fishnet %>%
mutate(
local_i = local_moran[, 1],
p_value = local_moran[, 5],
is_significant = p_value < 0.05
)
# Calculate mean for classification
mean_graffiti <- mean(fishnet$graffiti_count, na.rm = TRUE)
# Classify clusters
fishnet <- fishnet %>%
mutate(
moran_class = case_when(
!is_significant ~ "Not Significant",
local_i > 0 & graffiti_count > mean_graffiti ~ "High-High",
local_i > 0 & graffiti_count <= mean_graffiti ~ "Low-Low",
local_i < 0 & graffiti_count > mean_graffiti ~ "High-Low",
local_i < 0 & graffiti_count <= mean_graffiti ~ "Low-High",
TRUE ~ "Not Significant"
)
)
# Count each type
table(fishnet$moran_class)
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(st_geometry(fishnet)))
graffiti_coords <- st_coordinates(graffiti)
# Calculate k-nearest neighbors
if(nrow(graffiti) > 100000) {
cat("oversize (", nrow(graffiti), "items)，Random sampling resulted in 60,000 items.\n")
graffiti <- graffiti %>% slice_sample(n = 60000)
graffiti_coords <- st_coordinates(graffiti)
}
nn_result <- get.knnx(graffiti_coords, fishnet_coords, k = 3)
# Add to fishnet
fishnet <- fishnet %>%
mutate(
graffiti_nn = rowMeans(nn_result$nn.dist)
)
cat("Mean distance to 3 nearest graffiti locations:\n")
print(summary(fishnet$graffiti_nn))
ggplot() +
geom_sf(
data = fishnet,
aes(fill = moran_class),
color = NA
) +
scale_fill_manual(
values = c(
"High-High" = "#d7191c",
"High-Low" = "#fdae61",
"Low-High" = "#abd9e9",
"Low-Low" = "#2c7bb6",
"Not Significant" = "gray90"
),
name = "Cluster Type"
) +
labs(
title = "Local Moran's I: Graffiti Clusters",
subtitle = "High-High clusters indicate concentrated disorder hotspots"
) +
theme_crime()
# Get centroids of High-High cells
hotspots <- fishnet %>%
filter(moran_class == "High-High") %>%
st_centroid()
# Calculate distance to nearest hotspot
if (nrow(hotspots) > 0) {
fishnet <- fishnet %>%
mutate(
dist_to_hotspot = as.numeric(
st_distance(st_centroid(fishnet), hotspots %>% st_union())
)
)
cat("Number of graffiti hotspot cells:", nrow(hotspots), "\n")
cat("Distance to hotspot summary:\n")
print(summary(fishnet$dist_to_hotspot))
} else {
fishnet <- fishnet %>%
mutate(dist_to_hotspot = 0)
cat("No significant hotspots identified\n")
}
# Spatial join with police districts
fishnet <- st_join(
fishnet,
policeDistricts,
join = st_within,
left = TRUE
) %>%
filter(!is.na(District))
cat("Number of police districts:", length(unique(fishnet$District)), "\n")
cat("Grid cells after joining districts:", nrow(fishnet), "\n")
# Create modeling dataset
fishnet_model <- fishnet %>%
st_drop_geometry() %>%
dplyr::select(
uniqueID,
District,
countBurglaries,
graffiti_count,
graffiti_nn,
dist_to_hotspot
) %>%
na.omit()
cat("Modeling dataset:\n")
cat("  Observations:", nrow(fishnet_model), "\n")
cat("  Variables:", ncol(fishnet_model), "\n")
# Fit Poisson regression
model_poisson <- glm(
countBurglaries ~ graffiti_count + graffiti_nn + dist_to_hotspot,
data = fishnet_model,
family = "poisson"
)
# Display results
summary(model_poisson)
# Calculate dispersion parameter
dispersion <- sum(residuals(model_poisson, type = "pearson")^2) /
model_poisson$df.residual
cat("Dispersion parameter:", round(dispersion, 2), "\n")
if (dispersion > 1.5) {
cat("Overdispersion detected - Negative Binomial model recommended\n")
} else {
cat("Poisson model appears appropriate\n")
}
# Fit Negative Binomial model
model_nb <- glm.nb(
countBurglaries ~ graffiti_count + graffiti_nn + dist_to_hotspot,
data = fishnet_model
)
# Display results
summary(model_nb)
# Compare models using AIC (lower is better)
cat("\nModel comparison:\n")
cat("Poisson AIC:", round(AIC(model_poisson), 1), "\n")
cat("Negative Binomial AIC:", round(AIC(model_nb), 1), "\n")
cat("Difference:", round(AIC(model_poisson) - AIC(model_nb), 1), "\n")
# Get unique districts
districts <- unique(fishnet_model$District)
cv_results <- tibble()
cat("Running Leave-One-Group-Out Cross-Validation...\n\n")
for (i in seq_along(districts)) {
test_district <- districts[i]
# Split data by district
train_data <- fishnet_model %>% filter(District != test_district)
test_data <- fishnet_model %>% filter(District == test_district)
# Fit model on training data
model_cv <- glm.nb(
countBurglaries ~ graffiti_count + graffiti_nn + dist_to_hotspot,
data = train_data
)
# Predict on test data
test_data <- test_data %>%
mutate(
prediction = predict(model_cv, test_data, type = "response")
)
# Calculate error metrics
mae <- mean(abs(test_data$countBurglaries - test_data$prediction))
rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))
# Store results
cv_results <- bind_rows(
cv_results,
tibble(
fold = i,
test_district = test_district,
n_test = nrow(test_data),
mae = mae,
rmse = rmse
)
)
cat("Fold", i, "/", length(districts), "- District", test_district,
"- MAE:", round(mae, 2), "\n")
}
cat("\nCross-validation complete\n")
cat("Mean MAE:", round(mean(cv_results$mae), 2), "burglaries per cell\n")
cat("Mean RMSE:", round(mean(cv_results$rmse), 2), "burglaries per cell\n")
cv_results %>%
arrange(desc(mae)) %>%
mutate(across(c(mae, rmse), ~round(., 2))) %>%
kable(
caption = "Spatial Cross-Validation Results by Police District",
col.names = c("Fold", "District", "N Test", "MAE", "RMSE")
) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
# Fit final model on all 2017 data
final_model <- glm.nb(
countBurglaries ~ graffiti_count + graffiti_nn + dist_to_hotspot,
data = fishnet_model
)
# Add predictions to fishnet
fishnet <- fishnet %>%
mutate(
prediction_nb = predict(
final_model,
fishnet_model,
type = "response"
)[match(uniqueID, fishnet_model$uniqueID)]
)
# Normalize KDE to same scale
kde_sum <- sum(fishnet$kde_value, na.rm = TRUE)
count_sum <- sum(fishnet$countBurglaries, na.rm = TRUE)
fishnet <- fishnet %>%
mutate(
prediction_kde = (kde_value / kde_sum) * count_sum
)
# Create comparison maps
p1 <- ggplot() +
geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +
scale_fill_viridis_c(name = "Count", option = "plasma", limits = c(0, 15)) +
labs(title = "Actual Burglaries (2017)") +
theme_crime()
p2 <- ggplot() +
geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +
scale_fill_viridis_c(name = "Predicted", option = "plasma", limits = c(0, 15)) +
labs(title = "Model Predictions (Neg. Binomial)") +
theme_crime()
p3 <- ggplot() +
geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +
scale_fill_viridis_c(name = "Predicted", option = "plasma", limits = c(0, 15)) +
labs(title = "KDE Baseline Predictions") +
theme_crime()
p1 + p2 + p3
# Calculate performance metrics
comparison <- fishnet %>%
st_drop_geometry() %>%
filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%
summarize(
model_mae = mean(abs(countBurglaries - prediction_nb)),
model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),
kde_mae = mean(abs(countBurglaries - prediction_kde)),
kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))
)
comparison %>%
pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
separate(metric, into = c("approach", "metric"), sep = "_") %>%
pivot_wider(names_from = metric, values_from = value) %>%
mutate(across(where(is.numeric), ~round(., 2))) %>%
kable(
caption = "Model Performance Comparison on 2017 Data",
col.names = c("Approach", "MAE", "RMSE")
) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
# Calculate errors
fishnet <- fishnet %>%
mutate(
error_nb = countBurglaries - prediction_nb,
abs_error_nb = abs(error_nb)
)
# Map signed errors
p1 <- ggplot() +
geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +
scale_fill_gradient2(
name = "Error",
low = "#2166ac", mid = "white", high = "#b2182b",
midpoint = 0,
limits = c(-10, 10)
) +
labs(
title = "Model Errors (Actual - Predicted)",
subtitle = "Blue = under-predicted, Red = over-predicted"
) +
theme_crime()
# Map absolute errors
p2 <- ggplot() +
geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +
scale_fill_viridis_c(name = "Abs. Error", option = "magma") +
labs(
title = "Absolute Model Errors",
subtitle = "Magnitude of prediction errors"
) +
theme_crime()
p1 + p2
# Load 2018 burglaries from Chicago crimes dataset
burglaries_2018 <- read_csv(here("data", "Crimes_-_2018.csv")) %>%
# Filter for burglary crimes only
filter(`Primary Type` == "BURGLARY") %>%
# Further filter for forcible entry to match 2017 data
filter(str_detect(Description, "FORCIBLE ENTRY")) %>%
# Remove records with missing coordinates
filter(!is.na(Latitude), !is.na(Longitude)) %>%
# Remove invalid coordinates
filter(Latitude > 41.6, Latitude < 42.1) %>%
filter(Longitude > -87.95, Longitude < -87.5) %>%
# Convert to spatial object
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>%
st_transform('ESRI:102271')
